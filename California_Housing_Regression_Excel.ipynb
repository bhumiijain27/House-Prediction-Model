{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400b3242",
   "metadata": {},
   "source": [
    "\n",
    "# California Housing — Simple & Multiple Linear Regression\n",
    "\n",
    "Author: shobhit pandit \n",
    "Date: 28-8-2025  \n",
    "\n",
    "## 1. Overview\n",
    "This notebook predicts median house value for California districts using district-level features.\n",
    "We build and compare:\n",
    "- Simple Linear Regression (SLR) — using the single best predictor\n",
    "- Multiple Linear Regression (MLR) — using all relevant predictors via a preprocessing pipeline\n",
    "\n",
    "We cover complete EDA, preprocessing, model development, evaluation, and final model selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32df0da3",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Problem Statement\n",
    "Objective:Predict `median_house_value` using features such as income, rooms, bedrooms, population, households, housing age, latitude/longitude, and `ocean_proximity` (categorical).  \n",
    "We will:\n",
    "1. Explore & visualize the data.\n",
    "2. Preprocess (handle missing values, encode categoricals, scale numeric features if needed).\n",
    "3. Train SLR & MLR models.\n",
    "4. Evaluate with regression metrics: MSE, RMSE, MAE, R².\n",
    "5. Compare models for a balance of accuracy and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e7f2883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Paths ===\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path(\"Data_file.xlsx\")   \n",
    "TARGET_COL = \"median_house_value\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bff91",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69bdc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting (matplotlib only, no seaborn)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modeling\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Saving model\n",
    "import joblib\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69179b63",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1e6846",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find Data_file.xlsx",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DATA_PATH.exists():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m      3\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not find \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     )\n\u001b[32m      6\u001b[39m df = pd.read_excel(DATA_PATH)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, df.shape)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Could not find Data_file.xlsx"
     ]
    }
   ],
   "source": [
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find {DATA_PATH}\"\n",
    "    )\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee88c4",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Quick Data Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12707405",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic info\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"\\nData types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing values:\\n\", df.isna().sum())\n",
    "\n",
    "# Basic descriptive stats for numeric columns\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390fd8cc",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Exploratory Data Analysis (EDA)\n",
    "### 7.1 Target Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e32a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "df[TARGET_COL].hist(bins=50)\n",
    "plt.title(\"Distribution of Target: \" + TARGET_COL)\n",
    "plt.xlabel(TARGET_COL)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879a52b",
   "metadata": {},
   "source": [
    "\n",
    "### 7.2 Numeric Feature Histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356fa870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if TARGET_COL in numeric_cols:\n",
    "    numeric_cols.remove(TARGET_COL)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure()\n",
    "    df[col].hist(bins=50)\n",
    "    plt.title(f\"Histogram: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7226da5",
   "metadata": {},
   "source": [
    "\n",
    "### 7.3 Correlation Heatmap (Numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b98bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corr = df.select_dtypes(include=[np.number]).corr()\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(corr, interpolation='nearest', aspect='auto')\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.title(\"Correlation Heatmap (Numeric)\")\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "corr[TARGET_COL].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295b1a3",
   "metadata": {},
   "source": [
    "\n",
    "### 7.4 Target vs. Individual Predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_corr = corr[TARGET_COL].drop(labels=[TARGET_COL]).abs().sort_values(ascending=False)\n",
    "top_features = top_corr.head(6).index.tolist()\n",
    "\n",
    "for col in top_features:\n",
    "    plt.figure()\n",
    "    plt.scatter(df[col], df[TARGET_COL], alpha=0.3)\n",
    "    plt.title(f\"{TARGET_COL} vs {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(TARGET_COL)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265fc70",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Data Preprocessing\n",
    "- Impute missing numeric values with **median**.\n",
    "- One-hot encode **categorical** variables (e.g., `ocean_proximity`).\n",
    "- Optionally, **scale** numeric features (useful for some models; linear regression is scale-invariant for OLS, but scaling can help numeric stability).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e0837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify features\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", drop=None, sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8290cd4d",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Simple Linear Regression (SLR)\n",
    "We choose the **single most correlated numeric feature** with the target and fit a univariate linear regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31a984",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select best single numeric predictor by absolute correlation\n",
    "num_corr = df[numeric_features + [TARGET_COL]].corr()[TARGET_COL].drop(labels=[TARGET_COL])\n",
    "best_feature = num_corr.abs().sort_values(ascending=False).index[0]\n",
    "print(\"Best single predictor:\", best_feature)\n",
    "\n",
    "X_train_slr = X_train[[best_feature]].copy()\n",
    "X_test_slr  = X_test[[best_feature]].copy()\n",
    "\n",
    "slr = LinearRegression()\n",
    "slr.fit(X_train_slr, y_train)\n",
    "\n",
    "y_pred_slr = slr.predict(X_test_slr)\n",
    "\n",
    "mse_slr = mean_squared_error(y_test, y_pred_slr)\n",
    "rmse_slr = np.sqrt(mse_slr)\n",
    "mae_slr = mean_absolute_error(y_test, y_pred_slr)\n",
    "r2_slr = r2_score(y_test, y_pred_slr)\n",
    "\n",
    "print(f\"SLR — Test MSE: {mse_slr:.2f}, RMSE: {rmse_slr:.2f}, MAE: {mae_slr:.2f}, R²: {r2_slr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot: Actual vs Predicted (SLR)\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred_slr, alpha=0.3)\n",
    "plt.title(\"SLR — Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()])\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "resid_slr = y_test - y_pred_slr\n",
    "plt.figure()\n",
    "plt.scatter(y_pred_slr, resid_slr, alpha=0.3)\n",
    "plt.axhline(0)\n",
    "plt.title(\"SLR — Residuals vs Fitted\")\n",
    "plt.xlabel(\"Fitted\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22dfa4",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Multiple Linear Regression (MLR)\n",
    "We use all relevant features via a preprocessing pipeline (imputation, one-hot encoding, scaling) with OLS LinearRegression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea234cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLR — Test MSE: 4908290571.35, RMSE: 70059.19, MAE: 50670.49, R²: 0.6254\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlr = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "mlr.fit(X_train, y_train)\n",
    "y_pred_mlr = mlr.predict(X_test)\n",
    "\n",
    "mse_mlr = mean_squared_error(y_test, y_pred_mlr)\n",
    "rmse_mlr = np.sqrt(mse_mlr)\n",
    "mae_mlr = mean_absolute_error(y_test, y_pred_mlr)\n",
    "r2_mlr = r2_score(y_test, y_pred_mlr)\n",
    "\n",
    "print(f\"MLR — Test MSE: {mse_mlr:.2f}, RMSE: {rmse_mlr:.2f}, MAE: {mae_mlr:.2f}, R²: {r2_mlr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaac542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cross-validation on training data (for more robust score estimation)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_r2_scores = cross_val_score(mlr, X_train, y_train, scoring=\"r2\", cv=cv)\n",
    "cv_rmse_scores = np.sqrt(-cross_val_score(mlr, X_train, y_train, scoring=\"neg_mean_squared_error\", cv=cv))\n",
    "\n",
    "print(\"MLR — CV R² (mean ± std): {:.4f} ± {:.4f}\".format(cv_r2_scores.mean(), cv_r2_scores.std()))\n",
    "print(\"MLR — CV RMSE (mean ± std): {:.2f} ± {:.2f}\".format(cv_rmse_scores.mean(), cv_rmse_scores.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41edbec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot: Actual vs Predicted (MLR)\n",
    "plt.figure()\n",
    "plt.scatter(y_test, y_pred_mlr, alpha=0.3)\n",
    "plt.title(\"MLR — Actual vs Predicted\")\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()])\n",
    "plt.show()\n",
    "\n",
    "# Residuals\n",
    "resid_mlr = y_test - y_pred_mlr\n",
    "plt.figure()\n",
    "plt.scatter(y_pred_mlr, resid_mlr, alpha=0.3)\n",
    "plt.axhline(0)\n",
    "plt.title(\"MLR — Residuals vs Fitted\")\n",
    "plt.xlabel(\"Fitted\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4caca",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Model Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Simple Linear Regression\", \"Multiple Linear Regression\"],\n",
    "    \"MSE\": [mse_slr, mse_mlr],\n",
    "    \"RMSE\": [np.sqrt(mse_slr), np.sqrt(mse_mlr)],\n",
    "    \"MAE\": [mae_slr, mae_mlr],\n",
    "    \"R2\": [r2_slr, r2_mlr]\n",
    "}).sort_values(by=\"RMSE\")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693bb996",
   "metadata": {},
   "source": [
    "\n",
    "## 12. Interpreting the MLR (Feature Effects)\n",
    "We extract the linear model coefficients with their transformed feature names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b47d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract feature names after preprocessing\n",
    "ct = mlr.named_steps[\"preprocess\"]\n",
    "ohe = None\n",
    "for name, trans, cols in ct.transformers_:\n",
    "    if name == \"cat\":\n",
    "        ohe = trans.named_steps[\"onehot\"]\n",
    "        cat_cols = list(cols)\n",
    "    elif name == \"num\":\n",
    "        num_cols = list(cols)\n",
    "\n",
    "feature_names = []\n",
    "# Numeric features (after scaler)\n",
    "feature_names.extend(num_cols)\n",
    "\n",
    "# One-hot-encoded categorical features\n",
    "if ohe is not None:\n",
    "    cat_feature_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
    "    feature_names.extend(cat_feature_names)\n",
    "\n",
    "# Coefficients\n",
    "coefs = mlr.named_steps[\"model\"].coef_\n",
    "coef_df = pd.DataFrame({\"feature\": feature_names, \"coef\": coefs}).sort_values(by=\"coef\", key=lambda s: s.abs(), ascending=False)\n",
    "coef_df.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adcdf56",
   "metadata": {},
   "source": [
    "\n",
    "## 13. Save Final Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained MLR pipeline\n",
    "MODEL_PATH = Path(\"final_mlr_pipeline.joblib\")\n",
    "joblib.dump(mlr, MODEL_PATH)\n",
    "MODEL_PATH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895f5358",
   "metadata": {},
   "source": [
    "\n",
    "## 14. Using the Saved Model\n",
    "```python\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "pipe = joblib.load(\"final_mlr_pipeline.joblib\")\n",
    "\n",
    "# Example: predict for new rows (must match training columns, including 'ocean_proximity' if used)\n",
    "new_data = pd.DataFrame([{\n",
    "    \"longitude\": -122.23,\n",
    "    \"latitude\": 37.88,\n",
    "    \"housing_median_age\": 41.0,\n",
    "    \"total_rooms\": 880.0,\n",
    "    \"total_bedrooms\": 129.0,\n",
    "    \"population\": 322.0,\n",
    "    \"households\": 126.0,\n",
    "    \"median_income\": 8.3252,\n",
    "    \"ocean_proximity\": \"NEAR BAY\"\n",
    "}])\n",
    "\n",
    "pipe.predict(new_data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3584b3bf-2635-41ff-988b-76dd10edeb5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
